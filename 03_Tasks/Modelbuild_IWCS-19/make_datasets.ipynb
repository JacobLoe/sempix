{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Datasets for Entailments (CapObj, CapReg)\n",
    "\n",
    "Create the caption / object and caption / region entailment data for testing the model building approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import configparser\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up config file (needs path; adapt env var if necessary); local imports\n",
    "\n",
    "# load config file, set up paths, make project-specific imports\n",
    "config_path = os.environ.get('VISCONF')\n",
    "if not config_path:\n",
    "    # try default location, if not in environment\n",
    "    default_path_to_config = '../../clp-vision/Config/default.cfg'\n",
    "    if os.path.isfile(default_path_to_config):\n",
    "        config_path = default_path_to_config\n",
    "\n",
    "assert config_path is not None, 'You need to specify the path to the config file via environment variable VISCONF.'        \n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config.read_file(f)\n",
    "\n",
    "corpora_base = config.get('DEFAULT', 'corpora_base')\n",
    "preproc_path = config.get('DSGV-PATHS', 'preproc_path')\n",
    "dsgv_home = config.get('DSGV-PATHS', 'dsgv_home')\n",
    "\n",
    "\n",
    "sys.path.append(dsgv_home + '/Utils')\n",
    "from utils import icorpus_code, plot_labelled_bb, get_image_filename, query_by_id\n",
    "from utils import plot_img_cropped, plot_img_ax, invert_dict, get_a_by_b\n",
    "\n",
    "sys.path.append('../../Common')\n",
    "from data_utils import load_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up preprocessed DataFrames. Slow!\n",
    "# These DataFrames are the result of pre-processing the original corpus data,\n",
    "# as per dsg-vision/Preprocessing/preproc.py\n",
    "\n",
    "df_names = ['mscoco_bbdf', 'refcoco_refdf', 'refcocoplus_refdf',\n",
    "            'vgregdf', 'vgimgdf', 'vgobjdf', 'vgreldf', 'vgattdf', 'cococapdf']\n",
    "df = load_dfs(preproc_path, df_names)\n",
    "\n",
    "# a derived DF, containing only those region descriptions which I was able to resolve\n",
    "df['vgpregdf'] = df['vgregdf'][df['vgregdf']['pphrase'].notnull() & \n",
    "                               (df['vgregdf']['pphrase'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersecting visual genome and coco captions.\n",
    "caption_coco_iids = list(set(df['cococapdf']['image_id'].tolist()))\n",
    "# regions for only those image for which we also have coco captions\n",
    "visgencocap_regdf = df['vgpregdf'].merge(pd.DataFrame(caption_coco_iids, columns=['coco_id']))\n",
    "# coco_image_ids for images with both caption and region\n",
    "vgcap_coco_iids = list(set(visgencocap_regdf['coco_id'].tolist()))\n",
    "# visgen_image_ids for images with both caption and region\n",
    "vgcap_vg_iids = list(set(visgencocap_regdf['image_id'].tolist()))\n",
    "\n",
    "# map coco_ids to visgen_ids, and back\n",
    "coco2vg = dict(visgencocap_regdf[['coco_id', 'image_id']].values)\n",
    "vg2coco = dict([(v,k) for k,v in coco2vg.items()])\n",
    "\n",
    "visgencocap_objdf = df['vgobjdf'].merge(pd.DataFrame(vgcap_vg_iids, columns=['image_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgobjdf_syned = df['vgobjdf'][~df['vgobjdf']['syn'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load up the nearest neighbour index of captions in embedding space\n",
    "ind = AnnoyIndex(512, metric='euclidean')\n",
    "ind.load(preproc_path + '/caps.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embedding index works via the row number in cococapdf, so need mapping\n",
    "\n",
    "# N.B.: this is actually lossy. This is the row of the *first* caption for that\n",
    "#  image. But there will also be other rows (captions) for same image.\n",
    "#  So, should really one to many mapping. But for purposes here, is ok.\n",
    "coco2row = dict(zip(df['cococapdf']['image_id'].tolist(), df['cococapdf'].index.tolist()))\n",
    "# This is also the reason which this here is not inverse of above:\n",
    "row2coco = dict(zip(df['cococapdf'].index.tolist(), df['cococapdf']['image_id'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seed the random generators**\n",
    "\n",
    "For reproducability, seed the random number generators. This will lead to reproducible creation of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_corpus</th>\n",
       "      <th>image_id</th>\n",
       "      <th>obj_id</th>\n",
       "      <th>syn</th>\n",
       "      <th>name</th>\n",
       "      <th>bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3875508</th>\n",
       "      <td>5</td>\n",
       "      <td>2417469</td>\n",
       "      <td>3136701</td>\n",
       "      <td>flower.n.01</td>\n",
       "      <td>purple flower</td>\n",
       "      <td>[253, 113, 66, 43]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         i_corpus  image_id   obj_id          syn           name  \\\n",
       "3875508         5   2417469  3136701  flower.n.01  purple flower   \n",
       "\n",
       "                         bb  \n",
       "3875508  [253, 113, 66, 43]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "df['vgobjdf'].sample(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caption / Object\n",
    "\n",
    "Format: `caption, object that is indeed in image (name + synset), object from some other image (name + synset)`. Note that no check is made whether the \"negative\" hypothesis object is or isn't in target image.\n",
    "\n",
    "This data makes two ways of evaluation possible: *Choice* (which one is the correct hypothesis), and *Prediction* (is this hypothesis correct?). The latter style means that there are two predictions for each row (one for the positive hypothesis, one for the negative one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 103 ms, total: 32.7 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_samples = 10000\n",
    "selected_capcocoiids = np.random.choice(vgcap_coco_iids, n_samples)\n",
    "sampled_names = vgobjdf_syned.sample(n_samples)[['name', 'syn']].values\n",
    "\n",
    "triples = []\n",
    "for this_cocoii, nhyp in zip(selected_capcocoiids, sampled_names):\n",
    "    prem = df['cococapdf'][df['cococapdf']['image_id'] == this_cocoii].sample()['caption'].values[0]\n",
    "    all_p_names = visgencocap_objdf[visgencocap_objdf['image_id'] == coco2vg[this_cocoii]]\n",
    "    if len(all_p_names) == 0:\n",
    "        continue\n",
    "    phyp, phyp_syn = all_p_names.sample()[['name', 'syn']].values[0]\n",
    "    triples.append((int(this_cocoii), prem, phyp, phyp_syn, 1))\n",
    "    triples.append((int(this_cocoii), prem, nhyp[0], nhyp[1], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370121,\n",
       " u'A bench sitting out in a field next to a tree.',\n",
       " u'table',\n",
       " u'table.n.02',\n",
       " 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "capobjdf = pd.DataFrame(triples, columns='image_id premise hypothesis hypothesis_syn label'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "capobjdf.sample(frac=1).to_csv('EntailOut/capobj.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caption / Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 79.1 ms, total: 31.6 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "selected_capcocoiids = np.random.choice(vgcap_coco_iids, n_samples)\n",
    "\n",
    "sampled_regions = df['vgpregdf'].sample(n_samples)['phrase rels'.split()].values\n",
    "#sampled_regions = [(e[0], e[1][0]) for e in sampled_regions]\n",
    "\n",
    "reg_triples = []\n",
    "for this_cocoii, nregion in zip(selected_capcocoiids, sampled_regions):\n",
    "    npreg, nrel = nregion\n",
    "    prem = df['cococapdf'][df['cococapdf']['image_id'] == this_cocoii].sample()['caption'].values[0]\n",
    "    all_p_regions = df['vgpregdf'][df['vgpregdf']['image_id'] == coco2vg[this_cocoii]]\n",
    "    if len(all_p_regions) == 0:\n",
    "        continue\n",
    "    ppreg, prel = all_p_regions.sample()[['phrase', 'rels']].values[0]\n",
    "    reg_triples.append((int(this_cocoii), prem, ppreg, prel, 1))\n",
    "    reg_triples.append((int(this_cocoii), prem, npreg, nrel, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246444</td>\n",
       "      <td>A long row of motor scooters on a city street.</td>\n",
       "      <td>windows in a building</td>\n",
       "      <td>[[2493630, IN, in.r.01, 3688836]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246444</td>\n",
       "      <td>A long row of motor scooters on a city street.</td>\n",
       "      <td>one cat is in the car</td>\n",
       "      <td>[[297622, IN, in.r.01, 297623]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                               1  \\\n",
       "0  246444  A long row of motor scooters on a city street.   \n",
       "1  246444  A long row of motor scooters on a city street.   \n",
       "\n",
       "                       2                                  3  4  \n",
       "0  windows in a building  [[2493630, IN, in.r.01, 3688836]]  1  \n",
       "1  one cat is in the car    [[297622, IN, in.r.01, 297623]]  0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(reg_triples).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "capregdf = pd.DataFrame(reg_triples, columns='image_id premise hypothesis hyp_rel label'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "capregdf.sample(frac=1).to_csv('EntailOut/capreg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "alt-ctrl-e"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
