{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*David Schlangen, 2019-03-24*\n",
    "\n",
    "# Task: Resolving Co-Reference / Predicting Model Size\n",
    "\n",
    "In the section on discourses in the denotations section, we have already briefly mentioned the task of co-reference resolution. If the image (model) is available, co-reference is established exophorically, via the anchoring in the image object. If we take away the image, the task must be tackled via linguistic evidence (and common-sense knowledge about scenes) alone. (It hence becomes an inference / entailment task more than one of denotation computation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "notebook"
    ]
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Latex, display\n",
    "\n",
    "pd.set_option('max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "notebook"
    ]
   },
   "outputs": [],
   "source": [
    "# Load up config file (needs path; adapt env var if necessary); local imports\n",
    "\n",
    "# load config file, set up paths, make project-specific imports\n",
    "config_path = os.environ.get('VISCONF')\n",
    "if not config_path:\n",
    "    # try default location, if not in environment\n",
    "    default_path_to_config = '../../clp-vision/Config/default.cfg'\n",
    "    if os.path.isfile(default_path_to_config):\n",
    "        config_path = default_path_to_config\n",
    "\n",
    "assert config_path is not None, 'You need to specify the path to the config file via environment variable VISCONF.'        \n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config.read_file(f)\n",
    "\n",
    "corpora_base = config.get('DEFAULT', 'corpora_base')\n",
    "preproc_path = config.get('DSGV-PATHS', 'preproc_path')\n",
    "dsgv_home = config.get('DSGV-PATHS', 'dsgv_home')\n",
    "\n",
    "\n",
    "sys.path.append(dsgv_home + '/Utils')\n",
    "from utils import icorpus_code, plot_labelled_bb, get_image_filename, query_by_id\n",
    "from utils import plot_img_cropped, plot_img_ax, invert_dict, get_a_by_b\n",
    "sys.path.append(dsgv_home + '/WACs/WAC_Utils')\n",
    "from wac_utils import create_word2den, is_relational\n",
    "sys.path.append(dsgv_home + '/Preproc')\n",
    "from sim_preproc import load_imsim, n_most_sim\n",
    "\n",
    "sys.path.append('../Common')\n",
    "from data_utils import load_dfs, plot_rel_by_relid, get_obj_bb, compute_distance_objs\n",
    "from data_utils import get_obj_key, compute_relpos_relargs_row, get_all_predicate\n",
    "from data_utils import compute_distance_relargs_row, get_rel_type, get_rel_instances\n",
    "from data_utils import compute_obj_sizes_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "notebook"
    ]
   },
   "outputs": [],
   "source": [
    "# Load up preprocessed DataFrames. Slow!\n",
    "# These DataFrames are the result of pre-processing the original corpus data,\n",
    "# as per dsg-vision/Preprocessing/preproc.py\n",
    "\n",
    "df_names = ['vgregdf', #'vgimgdf', 'vgobjdf', 'vgreldf',\n",
    "           ]\n",
    "df = load_dfs(preproc_path, df_names)\n",
    "\n",
    "# a derived DF, containing only those region descriptions which I was able to resolve\n",
    "df['vgpregdf'] = df['vgregdf'][df['vgregdf']['pphrase'].notnull() & \n",
    "                               (df['vgregdf']['pphrase'] != '')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-reference resolution is the task of determining whether a referring expression introduces a new entity into the discourse or not. We can create data for this task using the visual genome region annotation. Turning the set of region descriptions into a \"discourse\", we have gold truth information about whether a region description that is  added to the discourse introduces a new entity or talks about one that has previously been introduced.\n",
    "\n",
    "This is what a model would have to predict. The result then is a set of co-reference chains, or entity mentions (in order of ocurrence). From a more semantic point of view, the task entails determining the size of the intended model of the discourse; co-reference between two mentions here means that only one individual constant needs to be introduced into the model. This is how it is displayed below, with the maximal model size being the number of entity-denoting expressions (if we were to create a new individual constant for each), the minimal number being the number of entity-types in the discourse (and assuming that all mentions of the same type co-refer), and the actual size being the one indicated by the object resolution of the descriptions. A perfect resolution of the co-references would lead to that number. \n",
    "\n",
    "(Note that the example here is relies on the provided object identifiers to distinguish objects, but visual genome seems to have insuffiently consolidated on that score. To create a cleaner dataset, to make the judgement whether a new object is introduced or not, a test of overlap (intersection over union) between bounding boxes should be performed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "waves and white foam in the ocean\n",
      "    NEW: 2386745 (wave.n.01)\n",
      "    NEW: 2386746 (ocean.n.01)\n",
      "----------\n",
      "snake looking kite in the sky\n",
      "    NEW: 1914555 (kite.n.03)\n",
      "    NEW: 2546564 (sky.n.01)\n",
      "----------\n",
      "colorful kite in the sky\n",
      "    NEW: 2442774 (kite.n.03)\n",
      "    old type, new instance: 2442774 kite.n.03\n",
      "    NEW: 2442775 (kite.n.03)\n",
      "    old type, new instance: 2442775 kite.n.03\n",
      "    NEW: 2442776 (kite.n.03)\n",
      "    old type, new instance: 2442776 kite.n.03\n",
      "    NEW: 2442777 (kite.n.03)\n",
      "    old type, new instance: 2442777 kite.n.03\n",
      "    NEW: 2442778 (kite.n.03)\n",
      "    old type, new instance: 2442778 kite.n.03\n",
      "    NEW: 2442779 (sky.n.01)\n",
      "    old type, new instance: 2442779 sky.n.01\n",
      "----------\n",
      "path up the mountain\n",
      "    NEW: 2619007 (way.n.05)\n",
      "    NEW: 2619008 (mountain.n.01)\n",
      "----------\n",
      "white clouds in the sky\n",
      "    NEW: 2546563 (cloud.n.01)\n",
      "    OLD: 2546564 (sky.n.01)\n",
      "----------\n",
      "max model size: 14 || min model size: 7 || actual model size: 13\n",
      "\n",
      "======================================================================\n",
      "leg of a giraffe\n",
      "    NEW: 3249168 (leg.n.01)\n",
      "    NEW: 3249169 (giraffe.n.01)\n",
      "----------\n",
      "leg of a giraffe\n",
      "    NEW: 2736297 (leg.n.01)\n",
      "    old type, new instance: 2736297 leg.n.01\n",
      "    NEW: 2736298 (giraffe.n.01)\n",
      "    old type, new instance: 2736298 giraffe.n.01\n",
      "----------\n",
      "leg of a giraffe\n",
      "    NEW: 3441572 (leg.n.01)\n",
      "    old type, new instance: 3441572 leg.n.01\n",
      "    NEW: 3280259 (giraffe.n.01)\n",
      "    old type, new instance: 3280259 giraffe.n.01\n",
      "----------\n",
      "a leg of a giraffe\n",
      "    NEW: 3091354 (leg.n.01)\n",
      "    old type, new instance: 3091354 leg.n.01\n",
      "    NEW: 3091355 (leg.n.01)\n",
      "    old type, new instance: 3091355 leg.n.01\n",
      "    NEW: 3091356 (leg.n.01)\n",
      "    old type, new instance: 3091356 leg.n.01\n",
      "    NEW: 3091357 (leg.n.01)\n",
      "    old type, new instance: 3091357 leg.n.01\n",
      "    NEW: 3696527 (giraffe.n.01)\n",
      "    old type, new instance: 3696527 giraffe.n.01\n",
      "    NEW: 3091359 (giraffe.n.01)\n",
      "    old type, new instance: 3091359 giraffe.n.01\n",
      "----------\n",
      "a leg of a giraffe\n",
      "    NEW: 3155736 (leg.n.01)\n",
      "    old type, new instance: 3155736 leg.n.01\n",
      "    NEW: 3696523 (leg.n.01)\n",
      "    old type, new instance: 3696523 leg.n.01\n",
      "    OLD: 3696527 (giraffe.n.01)\n",
      "    OLD: 3280259 (giraffe.n.01)\n",
      "----------\n",
      "a leg of a giraffe\n",
      "    NEW: 3169419 (leg.n.01)\n",
      "    old type, new instance: 3169419 leg.n.01\n",
      "    NEW: 3696525 (leg.n.01)\n",
      "    old type, new instance: 3696525 leg.n.01\n",
      "    NEW: 3696526 (leg.n.01)\n",
      "    old type, new instance: 3696526 leg.n.01\n",
      "    OLD: 3280259 (giraffe.n.01)\n",
      "    OLD: 3696527 (giraffe.n.01)\n",
      "----------\n",
      "neck of a giraffe\n",
      "    NEW: 3026209 (neck.n.01)\n",
      "    NEW: 3696530 (neck.n.01)\n",
      "    old type, new instance: 3696530 neck.n.01\n",
      "    NEW: 3696529 (giraffe.n.01)\n",
      "    old type, new instance: 3696529 giraffe.n.01\n",
      "    OLD: 3280259 (giraffe.n.01)\n",
      "----------\n",
      "neck of a giraffe\n",
      "    NEW: 3200934 (neck.n.01)\n",
      "    old type, new instance: 3200934 neck.n.01\n",
      "    OLD: 3280259 (giraffe.n.01)\n",
      "----------\n",
      "a leg of a giraffe\n",
      "    NEW: 3188033 (leg.n.01)\n",
      "    old type, new instance: 3188033 leg.n.01\n",
      "    OLD: 3696527 (giraffe.n.01)\n",
      "----------\n",
      "neck of a giraffe\n",
      "    NEW: 3280258 (neck.n.01)\n",
      "    old type, new instance: 3280258 neck.n.01\n",
      "    NEW: 3280257 (neck.n.01)\n",
      "    old type, new instance: 3280257 neck.n.01\n",
      "    OLD: 3280259 (giraffe.n.01)\n",
      "    NEW: 3280260 (giraffe.n.01)\n",
      "    old type, new instance: 3280260 giraffe.n.01\n",
      "----------\n",
      "a pair of lions sitting on rocks\n",
      "    NEW: 3463020 (lion.n.01)\n",
      "    NEW: 3463021 (lion.n.01)\n",
      "    old type, new instance: 3463021 lion.n.01\n",
      "    NEW: 3463022 (rock.n.01)\n",
      "----------\n",
      "a giraffes long neck\n",
      "    NEW: 3303755 (giraffe.n.01)\n",
      "    old type, new instance: 3303755 giraffe.n.01\n",
      "    NEW: 3303756 (neck.n.01)\n",
      "    old type, new instance: 3303756 neck.n.01\n",
      "----------\n",
      "exposed rocks on the ground\n",
      "    NEW: 2956048 (rock.n.01)\n",
      "    old type, new instance: 2956048 rock.n.01\n",
      "    NEW: 2956049 (land.n.04)\n",
      "----------\n",
      "shrubs growing on a hillside\n",
      "    NEW: 3052270 (shrub.n.01)\n",
      "    NEW: 3052271 (hillside.n.01)\n",
      "----------\n",
      "brown spot on giraffe watching the animal in the back ground\n",
      "    NEW: 3696557 (topographic_point.n.01)\n",
      "    NEW: 3258877 (giraffe.n.01)\n",
      "    old type, new instance: 3258877 giraffe.n.01\n",
      "    NEW: 3696558 (animal.n.01)\n",
      "----------\n",
      "brown spot on giraffe watching the animal in the back ground\n",
      "    NEW: 2833735 (topographic_point.n.01)\n",
      "    old type, new instance: 2833735 topographic_point.n.01\n",
      "    OLD: 3696527 (giraffe.n.01)\n",
      "    NEW: 2833737 (animal.n.01)\n",
      "    old type, new instance: 2833737 animal.n.01\n",
      "    NEW: 2833738 (land.n.04)\n",
      "    old type, new instance: 2833738 land.n.04\n",
      "----------\n",
      "brown spot on giraffe watching the animal in the back ground\n",
      "    NEW: 3299909 (topographic_point.n.01)\n",
      "    old type, new instance: 3299909 topographic_point.n.01\n",
      "    NEW: 3299910 (topographic_point.n.01)\n",
      "    old type, new instance: 3299910 topographic_point.n.01\n",
      "    NEW: 3299911 (topographic_point.n.01)\n",
      "    old type, new instance: 3299911 topographic_point.n.01\n",
      "    OLD: 3696527 (giraffe.n.01)\n",
      "    OLD: 3280259 (giraffe.n.01)\n",
      "    OLD: 3696527 (giraffe.n.01)\n",
      "----------\n",
      "brown spot on the giraffe sitting down\n",
      "    NEW: 3445038 (topographic_point.n.01)\n",
      "    old type, new instance: 3445038 topographic_point.n.01\n",
      "    OLD: 3280259 (giraffe.n.01)\n",
      "----------\n",
      "Large lions behind giraffes.\n",
      "    NEW: 2769683 (lion.n.01)\n",
      "    old type, new instance: 2769683 lion.n.01\n",
      "    NEW: 2769684 (giraffe.n.01.)\n",
      "----------\n",
      "Dead tree on rocky soil.\n",
      "    NEW: 2812718 (tree.n.01)\n",
      "    NEW: 2812719 (dirt.n.02.)\n",
      "----------\n",
      "Giraffe looking toward lion.\n",
      "    NEW: 3174138 (giraffe.n.01)\n",
      "    old type, new instance: 3174138 giraffe.n.01\n",
      "    NEW: 3174139 (lion.n.01.)\n",
      "----------\n",
      "Giraffes in a group walking on rocks.\n",
      "    NEW: 3151688 (giraffe.n.01)\n",
      "    old type, new instance: 3151688 giraffe.n.01\n",
      "    NEW: 3151689 (rock.n.01.)\n",
      "----------\n",
      "Giraffe with horns with black tips.\n",
      "    OLD: 3696527 (giraffe.n.01)\n",
      "    NEW: 3540535 (horn.n.01)\n",
      "----------\n",
      "max model size: 67 || min model size: 16 || actual model size: 53\n",
      "\n",
      "======================================================================\n",
      "flowers are in the foreground\n",
      "    NEW: 546489 (flower.n.01)\n",
      "    NEW: 546490 (foreground.n.01)\n",
      "----------\n",
      "trees are in the background\n",
      "    NEW: 546491 (tree.n.01)\n",
      "    NEW: 546492 (background.n.02)\n",
      "----------\n",
      "the sky has puffy white clouds\n",
      "    NEW: 546493 (sky.n.01)\n",
      "    NEW: 546494 (cloud.n.01)\n",
      "----------\n",
      "another meadow is in the background\n",
      "    NEW: 546496 (hayfield.n.01)\n",
      "    OLD: 546492 (background.n.02)\n",
      "----------\n",
      "the head of a cow\n",
      "    NEW: 546497 (head.n.01)\n",
      "    NEW: 546498 (cow.n.01)\n",
      "----------\n",
      "the ear of a cow\n",
      "    NEW: 546499 (ear.n.01)\n",
      "    NEW: 546500 (cow.n.01)\n",
      "    old type, new instance: 546500 cow.n.01\n",
      "----------\n",
      "the hind legs of a cow\n",
      "    NEW: 546501 (leg.n.01)\n",
      "    OLD: 546498 (cow.n.01)\n",
      "----------\n",
      "the front leg of a cow\n",
      "    NEW: 546502 (leg.n.01)\n",
      "    old type, new instance: 546502 leg.n.01\n",
      "    OLD: 546498 (cow.n.01)\n",
      "----------\n",
      "a white cow on the grass\n",
      "    OLD: 546498 (cow.n.01)\n",
      "    NEW: 546488 (grass.n.01)\n",
      "----------\n",
      "a white flower on the plant\n",
      "    NEW: 546503 (flower.n.01)\n",
      "    old type, new instance: 546503 flower.n.01\n",
      "    NEW: 546504 (plant.n.01)\n",
      "----------\n",
      "a white cloud in the sky\n",
      "    NEW: 546505 (cloud.n.01)\n",
      "    old type, new instance: 546505 cloud.n.01\n",
      "    OLD: 546493 (sky.n.01)\n",
      "----------\n",
      "The sheep are in a field. \n",
      "    NEW: 546487 (sheep.n.01)\n",
      "    OLD: 546488 (field.n.01.)\n",
      "----------\n",
      "The plant has flowers. \n",
      "    OLD: 546504 (plant.n.01)\n",
      "    NEW: 546506 (flower.n.01.)\n",
      "----------\n",
      "Animals in the field.\n",
      "    OLD: 546487 (animal.n.01)\n",
      "    OLD: 546488 (field.n.01.)\n",
      "----------\n",
      "Trees in the field.\n",
      "    OLD: 546491 (tree.n.01)\n",
      "    OLD: 546488 (field.n.01.)\n",
      "----------\n",
      "Grass on the field.\n",
      "    NEW: 546509 (grass.n.01)\n",
      "    old type, new instance: 546509 grass.n.01\n",
      "    OLD: 546488 (field.n.01.)\n",
      "----------\n",
      "Flowers on the plants.\n",
      "    OLD: 546489 (flower.n.01)\n",
      "    OLD: 546504 (plant.n.01.)\n",
      "----------\n",
      "Rolling hills in the background.\n",
      "    NEW: 546510 (hill.n.01)\n",
      "    OLD: 546492 (background.n.02.)\n",
      "----------\n",
      "max model size: 36 || min model size: 16 || actual model size: 21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# deep caption with co-reference on object level\n",
    "def extr_disc_ref_pphr(pphr):\n",
    "    discourse_referents = []\n",
    "    for token in pphr.split():\n",
    "        subtoken = token.split('|')\n",
    "        if len(subtoken) > 1:\n",
    "            word = subtoken.pop(0)\n",
    "            id_syn_list = zip(subtoken[::2], subtoken[1::2])\n",
    "            discourse_referents.extend([(int(e[0]), e[1]) for e in id_syn_list])\n",
    "    return discourse_referents\n",
    "\n",
    "def cond_print(instr, show):\n",
    "    if show:\n",
    "        print(instr)\n",
    "\n",
    "def model_size_stats(df, image_id, show=False):\n",
    "    all_pphr = df[df['image_id'] == image_id][['phrase', 'pphrase']].values.tolist()\n",
    "    all_discourse_referents = []\n",
    "    all_types = set()\n",
    "    n_mentions = 0\n",
    "    for this_phr, this_pphr in all_pphr:\n",
    "        cond_print(this_phr, show)\n",
    "        this_disc_refs = extr_disc_ref_pphr(this_pphr)\n",
    "        n_mentions += len(this_disc_refs)\n",
    "        #print '   ', this_disc_refs\n",
    "        #this_disc_refs_ids, this_disc_ref_types = zip(*this_disc_refs)\n",
    "        for disc_ref, ref_type in this_disc_refs:\n",
    "            if disc_ref in all_discourse_referents:\n",
    "                cond_print(\"    OLD: %d (%s)\" % (disc_ref, ref_type), show)\n",
    "            else:\n",
    "                cond_print(\"    NEW: %d (%s)\" % (disc_ref, ref_type), show)\n",
    "                all_discourse_referents.append(disc_ref)\n",
    "                if ref_type in all_types:\n",
    "                    cond_print('    old type, new instance: %d %s' % (disc_ref, ref_type), show)\n",
    "                all_types.add(ref_type)\n",
    "        cond_print('-' * 10, show)\n",
    "    cond_print('max model size: %d || min model size: %d || actual model size: %d'\\\n",
    "                    % (n_mentions, len(all_types), len(all_discourse_referents)), show)\n",
    "    return n_mentions, len(all_types), len(all_discourse_referents)\n",
    "\n",
    "n_egs = 3\n",
    "\n",
    "for _ in range(n_egs):\n",
    "    print(\"=\" * 70)\n",
    "    ii = df['vgpregdf'].sample()['image_id'].values[0]\n",
    "    model_size_stats(df['vgpregdf'], ii, show=True)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the examples here show, these aren't particularly nice discourses. Many features of real discourses are missing here: real coherence, in the sense that the individual discourse units build on each other; cohesion, in the sense that discourse-new and discourse-old is properly signalled. But for the purposes here, this can be seen as a feature, as it removes all cues to this task other than semantic ones. To decide whether another mention of an entity type co-refers to a previous one, here a model really must reason about whether the event it occurs in is compatible, what number of entities of this type are likely to be found in a scene of this kind, and so on. This argues that this tasks is still interesting from a semantic perspective, even if a model trained on this data would not directly be transferable to real, natural text. (As a final note, however, it would be possible to annotate the image paragraphs for co-reference and test the model on them, or even train on that data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Natural Language Semantics with Pictures: Some Language & Vision Datasets and Potential Uses for Computational Semantics",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "../Common/joint.bib",
   "cite_by": "number",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "alt-ctrl-e",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
